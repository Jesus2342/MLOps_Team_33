{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 666 entries, 0 to 665\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Performance           666 non-null    object\n",
      " 1   Gender                666 non-null    object\n",
      " 2   Caste                 666 non-null    object\n",
      " 3   coaching              666 non-null    object\n",
      " 4   time                  666 non-null    object\n",
      " 5   Class_ten_education   666 non-null    object\n",
      " 6   twelve_education      666 non-null    object\n",
      " 7   medium                666 non-null    object\n",
      " 8   Class_ X_Percentage   666 non-null    object\n",
      " 9   Class_XII_Percentage  666 non-null    object\n",
      " 10  Father_occupation     666 non-null    object\n",
      " 11  Mother_occupation     666 non-null    object\n",
      "dtypes: object(12)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Get route of the path\n",
    "current_path = os.getcwd()\n",
    "aux_curr_path = current_path\n",
    "project_path = aux_curr_path.replace('/notebooks', '')\n",
    "dataset_path = \"dataset/CEE_DATA.arff\"\n",
    "dataset_path = os.path.join(project_path, dataset_path)\n",
    "\n",
    "data, meta = arff.loadarff(dataset_path)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x) #Encoding from byte to string \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            #0 : Average -  157\n",
    "            #1 : Excellent - 101\n",
    "            #2 : Good - 210\n",
    "            #3 : Very Good - 198"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest=[\"Performance\",'Class_ X_Percentage', 'Class_XII_Percentage', 'medium', 'Caste']\n",
    "updated_df=df[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=updated_df.drop('Performance',axis=1)\n",
    "y= updated_df[['Performance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_ X_Percentage</th>\n",
       "      <th>Class_XII_Percentage</th>\n",
       "      <th>medium</th>\n",
       "      <th>Caste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>OBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>OBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Good</td>\n",
       "      <td>Vg</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Vg</td>\n",
       "      <td>Good</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Good</td>\n",
       "      <td>Vg</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Vg</td>\n",
       "      <td>Good</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class_ X_Percentage Class_XII_Percentage   medium    Caste\n",
       "0             Excellent            Excellent  ENGLISH  General\n",
       "1             Excellent            Excellent   OTHERS      OBC\n",
       "2             Excellent            Excellent  ENGLISH      OBC\n",
       "3             Excellent            Excellent   OTHERS  General\n",
       "4             Excellent            Excellent  ENGLISH  General\n",
       "..                  ...                  ...      ...      ...\n",
       "661                Good                   Vg  ENGLISH       ST\n",
       "662                  Vg                 Good  ENGLISH       ST\n",
       "663                Good                   Vg  ENGLISH       ST\n",
       "664                Good                 Good  ENGLISH       ST\n",
       "665                  Vg                 Good  ENGLISH       ST\n",
       "\n",
       "[666 rows x 4 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Performance\n",
       "0     Excellent\n",
       "1     Excellent\n",
       "2     Excellent\n",
       "3     Excellent\n",
       "4     Excellent\n",
       "..          ...\n",
       "661     Average\n",
       "662     Average\n",
       "663     Average\n",
       "664     Average\n",
       "665     Average\n",
       "\n",
       "[666 rows x 1 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create oneHot enconder object\n",
    "enc_OneHot = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "#Columns to apply one hot enconder\n",
    "col_X=['Class_ X_Percentage', 'Class_XII_Percentage', 'medium', 'Caste']\n",
    "\n",
    "\n",
    "#Create the transformer\n",
    "ct= ColumnTransformer(\n",
    "    transformers=[\n",
    "    (\"OneHotInXColumns\", enc_OneHot,col_X)\n",
    "                      ]\n",
    ")\n",
    "\n",
    "#Create Label encoder object\n",
    "ord_enc=LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Performance\n",
       "0     Excellent\n",
       "1     Excellent\n",
       "2     Excellent\n",
       "3     Excellent\n",
       "4     Excellent\n",
       "..          ...\n",
       "661     Average\n",
       "662     Average\n",
       "663     Average\n",
       "664     Average\n",
       "665     Average\n",
       "\n",
       "[666 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Applying OneHot to X\n",
    "X = ct.fit_transform(X)\n",
    "#Applying OneHot\n",
    "y_OneHot = enc_OneHot.fit_transform(y)\n",
    "\n",
    "#Applying LabelEnconder to y\n",
    "df[\"y_ord_enc\"]=ord_enc.fit_transform(y)\n",
    "y_Label = df[\"y_ord_enc\"]\n",
    "y_Label_array= np.array(y_Label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset for y_OneHot\n",
    "X_train, X_test, y_train_OneHot, y_test_OneHot = train_test_split(X, y_OneHot, test_size=0.2, random_state=42)\n",
    "\n",
    "#Split the dataset for y_Label (Pandas Series)\n",
    "X_train, X_test, y_train_Label, y_test_Label = train_test_split(X, y_Label, test_size=0.2, random_state=42)\n",
    "\n",
    "#Split the dataset for y_Label (Numpy array)\n",
    "X_train, X_test, y_train_Label_array, y_test_Label_array = train_test_split(X, y_Label_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.02185392, 0.0173769 , 0.02888012, 0.01741004, 0.0235858 ,\n",
      "       0.02088809, 0.0159409 , 0.012887  , 0.0205121 , 0.02207804,\n",
      "       0.01799798, 0.0170567 , 0.01220107, 0.02069402, 0.02823997,\n",
      "       0.01292682, 0.03099704, 0.02396703, 0.01617098, 0.01355076,\n",
      "       0.02585125, 0.0162251 , 0.0170629 , 0.0155921 , 0.01043391,\n",
      "       0.01446772, 0.020715  , 0.01673985, 0.01438403, 0.01128101]), 'score_time': array([0.00606585, 0.00291109, 0.0012691 , 0.00248981, 0.00097394,\n",
      "       0.00160193, 0.00100493, 0.00103617, 0.00206995, 0.00127316,\n",
      "       0.00144291, 0.00101805, 0.00265217, 0.007792  , 0.00066495,\n",
      "       0.00281715, 0.00123906, 0.00111103, 0.00104189, 0.00662613,\n",
      "       0.00104761, 0.00094891, 0.00334692, 0.00106525, 0.00191307,\n",
      "       0.00100923, 0.00159287, 0.00098014, 0.00082397, 0.00066113]), 'test_score': array([0.40298507, 0.43283582, 0.46268657, 0.49253731, 0.37313433,\n",
      "       0.41791045, 0.43939394, 0.51515152, 0.40909091, 0.45454545,\n",
      "       0.52238806, 0.3880597 , 0.43283582, 0.46268657, 0.43283582,\n",
      "       0.41791045, 0.51515152, 0.31818182, 0.42424242, 0.48484848,\n",
      "       0.41791045, 0.3880597 , 0.44776119, 0.37313433, 0.44776119,\n",
      "       0.43283582, 0.46969697, 0.46969697, 0.37878788, 0.36363636])}\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define SMOTE con `sampling_strategy` como un diccionario\n",
    "over = SMOTE(sampling_strategy={0: 178, 1: 178})  # Ajusta los valores para tus clases\n",
    "under = RandomUnderSampler(sampling_strategy={2: 178, 3: 178})  # Ajusta los valores de undersampling\n",
    "\n",
    "# Definir el pipeline con SMOTE y RandomUnderSampler\n",
    "steps = [('oversampling', over), ('undersampling', under), ('classifier', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Definir validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluar pipeline\n",
    "scores = cross_validate(pipeline, X, y_Label_array, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_ord_enc\n",
       "2    210\n",
       "3    198\n",
       "0    157\n",
       "1    101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With under-sampling methods, the number of samples in a class should be less or equal to the original number of samples. Originally, there is 74 samples and 200 samples are asked.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moversampling\u001b[39m\u001b[38;5;124m'\u001b[39m, over), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mundersampling\u001b[39m\u001b[38;5;124m'\u001b[39m, under), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, model)])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_Label_array)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Hacer predicciones con el conjunto de prueba\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py:293\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    292\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 293\u001b[0m Xt, yt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py:250\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    240\u001b[0m     X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    241\u001b[0m         cloned_transformer,\n\u001b[1;32m    242\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cloned_transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_resample\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 250\u001b[0m     X, y, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_resample_one_cached(\n\u001b[1;32m    251\u001b[0m         cloned_transformer,\n\u001b[1;32m    252\u001b[0m         X,\n\u001b[1;32m    253\u001b[0m         y,\n\u001b[1;32m    254\u001b[0m         message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    255\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py:422\u001b[0m, in \u001b[0;36m_fit_resample_one\u001b[0;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_resample_one\u001b[39m(sampler, X, y, message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m--> 422\u001b[0m         X_res, y_res \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39mfit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X_res, y_res, sampler\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/base.py:108\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py:536\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28msorted\u001b[39m(SAMPLING_TARGET_KIND[sampling_strategy](y, sampling_type)\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[0;32m--> 536\u001b[0m         \u001b[38;5;28msorted\u001b[39m(_sampling_strategy_dict(sampling_strategy, y, sampling_type)\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    537\u001b[0m     )\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28msorted\u001b[39m(_sampling_strategy_list(sampling_strategy, y, sampling_type)\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    541\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py:325\u001b[0m, in \u001b[0;36m_sampling_strategy_dict\u001b[0;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_sample, n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m>\u001b[39m target_stats[class_sample]:\n\u001b[0;32m--> 325\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith under-sampling methods, the number of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples in a class should be less or equal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to the original number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Originally, there is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_stats[class_sample]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples are asked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m             )\n\u001b[1;32m    332\u001b[0m         sampling_strategy_[class_sample] \u001b[38;5;241m=\u001b[39m n_samples\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: With under-sampling methods, the number of samples in a class should be less or equal to the original number of samples. Originally, there is 74 samples and 200 samples are asked."
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Definir la estrategia de oversampling para las clases minoritarias\n",
    "over = SMOTE(sampling_strategy={2: 180})  # Sobremuestrear las clases 0 y 1 a 150 ejemplos\n",
    "\n",
    "# Definir la estrategia de undersampling para las clases mayoritarias\n",
    "under = RandomUnderSampler(sampling_strategy={1:200})  # Submuestrear las clases 2 y 3 a 150 ejemplos\n",
    "\n",
    "#Maximos \n",
    "#0-126,\n",
    "#1-74\n",
    "#2-176\n",
    "#3-156-200?\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline(steps=[('oversampling', over), ('undersampling', under), ('classifier', model)])\n",
    "\n",
    "# Entrenar el modelo\n",
    "pipeline.fit(X_train, y_train_Label_array)\n",
    "\n",
    "# Hacer predicciones con el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test_Label_array, y_pred, target_names=[\"Clase 0\", \"Clase 1\", \"Clase 2\", \"Clase 3\"]))\n",
    "\n",
    "precision_macro = precision_score(y_test_Label_array, y_pred, average='macro')\n",
    "precision_weighted = precision_score(y_test_Label_array, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precisión promedio (macro): {precision_macro:.4f}\")\n",
    "print(f\"Precisión promedio (weighted): {precision_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Suponiendo que ya tienes el modelo entrenado y las predicciones\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generar el reporte de clasificación\u001b[39;00m\n\u001b[1;32m      7\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClase 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClase 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClase 2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClase 3\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Suponiendo que ya tienes el modelo entrenado y las predicciones\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Clase 0\", \"Clase 1\", \"Clase 2\", \"Clase 3\"])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el modelo y el pipeline con SMOTE y RandomUnderSampler\n",
    "model = DecisionTreeClassifier()\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('oversampling', over), ('undersampling', under), ('MyClassifier', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Define el esquema de validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evalúa el pipeline usando roc_auc_ovr para problemas multiclase\n",
    "scores = cross_validate(pipeline, X, y, scoring='roc_auc_ovr', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Experiments = [\n",
    "    (\n",
    "        \"Random Forest n_estimators=100\", \n",
    "        RandomForestClassifier(class_weight=\"balanced\"),\n",
    "        (X_train, y_train_OneHot),\n",
    "        (X_test, y_test_OneHot)\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"XGBoost\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        (X_train, y_train_OneHot),\n",
    "        (X_test, y_test_OneHot)\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "         \"Multinomial Logistic Regression\",\n",
    "        LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200),\n",
    "        (X_train, y_train_Label),\n",
    "        (X_test, y_test_Label)\n",
    "    ),\n",
    "    \n",
    "     (\n",
    "        \"K-Nearest Neighbors\",\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        (X_train, y_train_Label),\n",
    "        (X_test, y_test_Label)\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        \"MLP\",\n",
    "        MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, activation='relu', solver='adam'),\n",
    "        (X_train, y_train_OneHot),\n",
    "        (X_test, y_test_OneHot)\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        \"Support Vector Classifier\",\n",
    "        SVC(kernel='linear', probability=True),  \n",
    "        (X_train, y_train_Label),\n",
    "        (X_test, y_test_Label)\n",
    "    )\n",
    "    \n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_model = []\n",
    "\n",
    "for model_name, model, train_set, test_set in Experiments:\n",
    "    X_train = train_set[0] #get Xtrain from the list models\n",
    "    y_train = train_set[1] #get y_train from list models\n",
    "    X_test = test_set[0]    #get x_test from list models \n",
    "    y_test = test_set[1]   #get y_test from list models\n",
    "    \n",
    "    model.fit(X_train, y_train)  #train the current model\n",
    "    y_pred = model.predict(X_test) #make predictions \n",
    "    report = classification_report(y_test, y_pred, output_dict=True) #make a dict of the classification report\n",
    "    \n",
    "    \n",
    "    results_per_model.append(report) #add the previus dict to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish experiements to server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "mlflow.set_experiment(\"Student Performance Analysis Model\")\n",
    "mlflow.set_tracking_uri(\"http://3.84.228.208:5000\")\n",
    "\n",
    "for i, element in enumerate(Experiments):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = results_per_model[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "            mlflow.log_param(\"model\", model_name)\n",
    "            \n",
    "            \n",
    "            # -------------Class interpretation---------------- \n",
    "            #0 : Average\n",
    "            #1 : Excellent\n",
    "            #2 : Good\n",
    "            #3 : Very Good\n",
    "\n",
    "            #Metrics of class 0\n",
    "            \n",
    "            mlflow.log_metric('acurracy_class_0', report['0']['precision'])\n",
    "            mlflow.log_metric('recall_class_0', report['0']['recall'])\n",
    "            mlflow.log_metric('f1_class_0', report['0']['f1-score'])\n",
    "            \n",
    "            #Metrics of class 1\n",
    "             \n",
    "            mlflow.log_metric('acurracy_class_1', report['1']['precision'])\n",
    "            mlflow.log_metric('recall_class_1', report['1']['recall'])\n",
    "            mlflow.log_metric('f1_class_1', report['1']['f1-score'])\n",
    "            \n",
    "            #Metrics of class 2\n",
    "            \n",
    "            mlflow.log_metric('acurracy_class_2', report['2']['precision'])\n",
    "            mlflow.log_metric('recall_class_2', report['2']['recall'])\n",
    "            mlflow.log_metric('f1_class_2', report['2']['f1-score'])\n",
    "            \n",
    "            #Metrics of class 3\n",
    "            \n",
    "            mlflow.log_metric('acurracy_class_3', report['3']['precision'])\n",
    "            mlflow.log_metric('recall_class_3', report['3']['recall'])\n",
    "            mlflow.log_metric('f1_class_3', report['3']['f1-score'])\n",
    "            \n",
    "        \n",
    "            if \"XGB\" in model_name:\n",
    "                mlflow.xgboost.log_model(model, \"model\")\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(model, \"model\") \n",
    "                \n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
